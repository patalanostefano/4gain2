{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyBEsyakskQ7iZnDfnlDGQYwSB0QQJ5fMhA'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-flash')\n",
    "\n",
    "import json\n",
    "\n",
    "base_path = \"/content/drive/MyDrive/ocr_eval/\"  \n",
    "with open(base_path + \"cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cleaned = json.load(f)\n",
    "\n",
    "with open(base_path + \"4gain-hw2_ocr-Qwen2-1.5B-chunked-keys1to6-10000tokens.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corrected = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(reference, candidate):\n",
    "    return f\"\"\"Sei un giudice della qualità di testo.  \n",
    "Riferimento (testo pulito):  \n",
    "\\\"\\\"\\\"{reference}\\\"\\\"\\\"  \n",
    "\n",
    "Candidato (output del modello):  \n",
    "\\\"\\\"\\\"{candidate}\\\"\\\"\\\"  \n",
    "\n",
    "Valuta il candidato su quattro aspetti (punteggio intero 1–5):  \n",
    "1. Grammatica (1 = grammatica molto innaturale, 5 = perfettamente corretto e in italiano naturale)  \n",
    "2. Fedeltà (1 = significato cambiato, 5 = significato esattamente preservato)  \n",
    "3. Pulizia (1 = molti errori OCR, 5 = nessun errore OCR)  \n",
    "4. Punteggiatura (1 = molti errori di punteggiatura, 5 = punteggiatura perfetta)  \n",
    "\n",
    "Restituisci un JSON esatto:\n",
    "{{\n",
    "  \"fluidita\": <int 1–5>,\n",
    "  \"fedelta\": <int 1–5>,\n",
    "  \"pulizia\": <int 1–5>,\n",
    "  \"punteggiatura\": <int 1–5>,\n",
    "  \"commento\": \"<giustificazione in una frase>\"\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval loop (keys 1 to 6)\n",
    "import time\n",
    "\n",
    "eval_results = []\n",
    "ids = [str(i) for i in range(1, 7)]\n",
    "\n",
    "for idx in ids:\n",
    "    reference = cleaned[idx]\n",
    "    candidate = corrected[idx]\n",
    "    prompt = build_prompt(reference, candidate)\n",
    "\n",
    "    # Gemini inference with retry\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            response = model.generate_content(prompt, generation_config={\"temperature\": 0})\n",
    "            output_text = response.text\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Retrying for ID {idx} due to: {e}\")\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Failed on ID {idx}\")\n",
    "        continue\n",
    "\n",
    "    # Extract JSON from Gemini output\n",
    "    try:\n",
    "        parsed = json.loads(output_text)\n",
    "    except Exception:\n",
    "        print(f\"❌ Parsing failed for ID {idx}. Output:\\n{output_text}\")\n",
    "        continue\n",
    "\n",
    "    parsed.update({\n",
    "        \"id\": int(idx),\n",
    "        \"model\": \"Qwen2-1.5B\"\n",
    "    })\n",
    "    eval_results.append(parsed)\n",
    "    time.sleep(1)  # Respectful delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = base_path + \"outputs/4gain-hw2_ocr-judge_gemini_it.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Saved:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cerbero_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:14:12) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cf22feda69b4074950813c1182d8f5bad8a3a5912d08aee91313df745d21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
